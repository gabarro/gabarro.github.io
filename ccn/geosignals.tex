\title{Geometric Signals}



\newcommand{\1}{\mathbf{1}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\T}{\mathbf{T}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\ud}{\mathrm{d}}
\newcommand{\ds}{\displaystyle}

To study a geometric object~$M$, people often use regular functions
between~$M$ and spaces with well-known properties, such as~$\R^n$,~$\T^n$
or~$S^n$.  The resulting spaces of functions have an algebraic structure
whose properties correspond to geometric properties of~$M$.
Thus, the number of connected components, number of holes, etc, arise as
dimensions of vector spaces or cardinals of groups.
Typically,
families of functions of the form~$X^n\to M$ constitute a sequence of groups
(homology, homotopy), and the structure of these groups and their quotients
 lot of geometrical information about~$M$.  On the other hand,
families of functions~$M\to X^n$ form a sequence of vector spaces
(cohomology) whose dimensions and quotients give geometrical information
about~$M$, in a different, often easier to interpret form.

The easiest example is the algebraic definition of~\emph{connexity}.  Imagine
that~$M$ has~$n$ connected components.  How can we recover~$n$ using this kind
of algebra?
%
Via cohomology: consider the set of smooth functions~$M\to\R$ whose
derivative is zero.  This set is a vector space of dimension~$n$.
Notice that this is the quotient space of the set of all smooth functions,
modulo its subspace defined by a linear condition~$df=0$.
%
Via homology: consider the free abelian group generated by all
paths~$[0,1]^1\to M$.  The boundary of such a path is defined as the difference
between its two endpoints, which is an element of the free group generated by
all points~$[0,1]^0\to M$.  The quotient of two such groups is isomorphic
to~$\Z^n$.

Functions~$\R\to M$ are thus called~\emph{paths} or~\emph{walks},
or~\emph{trajectories}.  And functions~$M\to\R$ will be called
called~\emph{signals}, or simply~\emph{functions}.

In this note we recall the main definitions of ``geometric signal
processing''. That is, we study the many operations that can be performed with
sets of functions of the form~$M\to X^n$.  We just give the definitions and
the main main results; no proofs nor lengthy interpretations.


\clearpage
\section{Vector calculus}

\subsection{vector calculus in the plane}

\subsection{vector calculus in three-dimensional space}

\subsection{integral theorems: green, gauss, stokes}

\subsection{limitations of vector calculus (e.g. two types of vector fields)}

\subsection{geometry of plane curves, space curves, surfaces}


\clearpage
\section{Differential geometry}

% GRAND SCHEME OF NON-METRIC STUFF, SUBSET OF NEXT SECTION'S SCHEME

\subsection{manifolds, charts, atlases}

The easiest way to think of a manifold is as~$\R^n$, but where most operations
are forbidden: you cannot sum points, multiply points by scalars,
nor compute inner products.  There is no notion of translation, nor
symmetry.  What~\emph{can} you do, then?  You can only have smooth
curves~$\R\to M$ and functions~$M\to\R$, and relations between
these two objects.  Notice that if you have a curve~$\gamma:\R\to M$ and a
function~$f:M\to\R$ then the composition~$f\circ\gamma$ is a
function~$\R\to\R$ upon which it is straightforward to reason.

Formally, a differential manifold is defined as a topological space~$M$
together with a set of charts, that is, continuous bijective
functions~$\varphi:U\to\R^n$, where~$U$ are open sets of~$M$, such that for
any pair of charts~$\varphi,\varphi'$ the
function~$\varphi'\circ\varphi^{-1}$ is a smooth diffeomorphism of~$\R^n$
(nonempty if~$U\cap U'\neq\emptyset$).  A trivial example is~$\R^n$ itself,
with the identity function as its only chart.

An equivalent definition (but the equivalence is non-trivial) is that an
$n$-dimensional manifold is set of the form~$F^{-1}(\{0\})$
where~$F:\R^{n+k}\to\R^n$ is a smooth function such that~$0$ is not a
critical value.

A mapping~$f:M\to N$ between manifolds is said to be smooth when for any
charts~$\varphi:U\to\R^m$, $\psi:V\to\R^n$ the
mapping~$\psi\circ\varphi^{-1}:\R^m\to\R^n$ is smooth.
As particular cases  of this definition you have smooth curves and smooth
signals.

The ring of smooth signals on~$M$ is denoted by~$C^\infty(M)$.

\subsection{tangent vectors, vector fields, tangent bundle}

There are several equivalent ways to define~\emph{tangent vectors}.
Let~$p$ be a point of a manifold~$M$.

(T1) A tangent vector~$X_p$ at the point~$p$ is an equivalence class of
curves~$\gamma:\R\to M$ through~$p$ (i.e., such that~$\gamma(0)=p$)
modulo the equivalence relation
\[
	\gamma_1\sim\gamma_2
	\iff
		(\varphi\circ\gamma_1)'(0)=(\varphi\circ\gamma_2)'(0)
\]
for all charts~$\varphi:U\to\R^n$ such that~$p\in U$.  Notice that this
definition makes sense because the maps~$\varphi\circ\gamma_i$ are smooth
functions~$\R\to\R^n$.

(T2) A tangent vector~$X_p$ at the point~$p$ is a linear derivation on the
ring~$C^\infty(M)$.  That is, an~$\R$-linear and~$C^\infty(M)$-additive
function~$X_p:C^\infty(M)\to\R$ such that
\[
	X_p(fg)=f(p)X_p(g) + g(p)X_p(f)
\]
for all~$f,g\in C^\infty(M)$.  The number~$X_p(f)$ is to be interpreted as
the directional derivative of the function~$f$ in the direction of the
vector~$X_p$.  Notice that an immediate consequence of the definition is
that~$X_p(c)=0$ for constant functions~$c$.

(T3) If~$\varphi$ is a local chart around~$p$, a tangent vector at~$p$ is
given by~$n$ numbers~$(x^1,\ldots,x^n)\in\R^n$, called ``the coordinates of
the vector in the chart~$\varphi$''.

For the last definition to make sense, we need a way to say whether vectors
given by coordinates in different charts are equal.  This happens when their
coordinates are linearly related by the jacobian matrix of the
map~$\varphi'\circ\varphi^{-1}:\R^n\to\R^n$.  To see in what order the matrix
product happens, look at the simplest example:~$M=\R^n$, one chart being the
identity map and the other one an arbitrary diffeomorphism.

The~\emph{tangent space} of~$M$ at~$p$ is the set~$T_pM$ of all tangent
vectors at~$p$.  It happens to be a vector space of dimension~$n$.

A~\emph{vector field} is the assignment of a tangent vector to each point of
the manifold.  This definition is not very operational if we want to talk
about how regular a vector field is, etc.  The appropriate definition of
vector field is a section of the so-called~\emph{tangent bundle}~$TM$, that
must be defined first.  The tangent bundle is the union of all tangent
spaces~$TM=\bigcup_{p\in M}T_pM$.  It happens to be a manifold of
dimension~$2m$, and it is equipped with the natural projection
operator~$\pi:TM\to M$ that recovers the base point of each
vector:~$\pi\left(X_p\right)=p$.  There are like seven different definitions
of the tangent bundle, and Spivak's monograph spends a large amount of the
first volume to prove that all these definitions are equivalent.

Here, we recall the following definitions of a vector field.  Definitions
F1,F2,F3 mirror the definitions T1,T2,T3 of a tangent vector, but F0 is
different:

(F0) A vector field is a section of the tangent bundle, that is a
smooth map~$X:M\to TM$ such that~$\pi\circ X$ is the identity on~$M$.

(F1) A vector field is given by a local flow field, i.e., a smooth
function~$\phi:M\times\R\mapsto M$ such that~$\phi(p,0)=p$.

(F2) A vector field is an~$\R$-linear derivation, i.e. a linear
map~$X:C^\infty(M)\to C^\infty(M)$ such that
\[
	X(fg)=fX(g)+gX(f)
\]
for all~$f,g\in C^\infty(M)$.

(F3) A vector field is given on a coordinate chart by a set of~$n$
functions~$a^i:\R^n\to\R$ called the components of the field on that
coordinate system.  Changes of coordinates follow the same law as in (T3).

The set of all vector fields is denoted~$\mathcal{X}(M)$.
It is an~$\R$-vector space and a~$C^\infty(M)$-module.

The canonical basis of~$T_p\R^d$
is~$\displaystyle\left\{\left.\frac{\partial}{\partial
	x^i}\right|_p\right\}_{i=1,\ldots,d}$.  Any vector
	field~$X\in\mathcal{X}(\R^d)$ can thus be written uniquely as
\[
	X =
	a^1\frac{\partial}{\partial x^1}
	+\cdots+
	a^d\frac{\partial}{\partial x^d}
\]
where~$a^1,\ldots,a^d\in C^\infty(M)$.

\subsection{tensors, tensor product, contraction}

%SCRIPT gnuplot >gs_p.png <<EOF
%SCRIPT set term pngcairo size 320,200 enhanced font "BaskervaldADFStd,22"
%SCRIPT set nokey ; set notics ; set noborder
%SCRIPT set label "{/:Italic p}" at 0.5,-0.5
%SCRIPT plot [-2:3] [-2:3] '-' using 1:2 w points pt 7 ps 2 lc rgb 'black'
%SCRIPT      0 0
%SCRIPT      e
%SCRIPT EOF

%SCRIPT gnuplot >gs_Xp.png <<EOF
%SCRIPT set term pngcairo size 320,200 enhanced font "BaskervaldADFStd,22"
%SCRIPT set nokey ; set notics ; set noborder
%SCRIPT set arrow 1 from 0,0 to 3,2 filled
%SCRIPT set label "X_{/:Italic p}" at 3.5,1.5
%SCRIPT set label "{/:Italic p}" at 0.5,-0.5
%SCRIPT plot [-1:4] [-1:4] '-' using 1:2 w points pt 7 ps 2 lc rgb 'black'
%SCRIPT      0 0
%SCRIPT      e
%SCRIPT EOF

%SCRIPT gnuplot >gs_wp.png <<EOF
%SCRIPT set term pngcairo size 320,200 enhanced font "BaskervaldADFStd,22"
%SCRIPT set nokey ; set notics ; set noborder
%SCRIPT set lmargin 0
%SCRIPT set tmargin 0
%SCRIPT set bmargin 0
%SCRIPT set tmargin 0
%SCRIPT set label '' at 0,0 left offset char 2,0 point pt 7 ps 2 lc 0
%SCRIPT set label "ω_{/:Italic p}" at 1.9,1.2
%SCRIPT set label "{/:Italic p}" at -0.05,-0.5
%SCRIPT unset surface
%SCRIPT set view map
%SCRIPT unset table
%SCRIPT set contour base
%SCRIPT set cntrparam levels 13
%SCRIPT set for [i=1:8] linetype i linecolor 0
%SCRIPT splot [-2:2] [-2:2] 15*x-2*y
%SCRIPT EOF

\begin{tabular}{ccc}
	\includegraphics[width=0.3\linewidth]{gs_p.png} &
	\includegraphics[width=0.3\linewidth]{gs_Xp.png} &
	\includegraphics[width=0.3\linewidth]{gs_wp.png} \\
	A point~$p$ &
	A tangent vector~$X_p$ &
	A tangent covector~$\omega_p$
\end{tabular}

Let~$V$ be a vector space.  Elements of~$V$ are called~\emph{vectors} and
elements of its dual~$V^*$ are called~\emph{covectors}.
Thus if~$X\in V$ and~$\omega\in V^*$ then~$\omega(X)$ is a scalar.
You can think of~$V$ as ``column vectors'' and~$V^*$ as ``row vectors'', but
this is a somewhat limited view.

A~\emph{tensor of type~$(r,s)$} is a by definition multilinear map
\[
	\left(V^*\right)^r\times V^s\to\R.
\]
Thus a scalar is a tensor of type~$(0,0)$, a vector is a tensor of
type~$(1,0)$, a covector is a tensor of type~$(0,1)$, a linear map is a
tensor of type~$(1,1)$ and a bilinear form is a tensor of type~$(0,2)$.
If~$V$ is~$d$-dimensional, the set of tensors of type~$(r,s)$ has
dimension~$d^{r+s}$.

The~\emph{tensor product} of two tensors~$T\otimes T'$ is defined in a natural
way and is a tensor of type~$(r+r',s+s')$.

By setting~$V=T_pM$ we obtain a family of tangent tensor spaces.  Those can
be lifted to~\emph{tensor fields}: we denote by~$\mathcal{T}^{r,s}(M)$ is the
set of all tensor fields of type~$(r,s)$ on~$M$.
Thus~$\mathcal{T}^{0,0}(M)=C^\infty(M)$
and~$\mathcal{T}^{1,0}=\mathcal{X}(M)$.

Recall Penrose graphical notation and abstract index notation using Einstein
summation.

Tangent vectors at~$p$: the velocity of a curve~$\R\to M$
through~$p$.  Tangent covectors: the gradient of a function~$M\to\R$ at~$p$.

If~$X$ is a vector field and~$T$ is a tensor field of type~$(r,s)$
with~$s>0$, then the~\emph{contraction} of~$T$ by~$X$ is the tensor
field~$i_XT$ of
type~$(r,s-1)$ obtained by plugging~$X$ into the first slot of~$T$.

\subsection{differential forms, wedge product}

Tensor fields of type~$(0,p)$ that are alternating are
called~\emph{differential forms} of degree~$p$, or simply~$p$-forms.
The set of~$p$-forms on~$M$ is denoted by~$\Omega^p(M)$.
Any tensor field of type~$(0,p)$ can be anti-symmetrized by summing over all
permutations of its inputs, weighted by the sign of each permutation.  Thus,
for~$p=2$, the tensor field~$(x,y)\mapsto\frac{T(x,y)-T(y,x)}2$ is
a~$2$-form.

If~$V$ is~$d$-dimensional, the set of anti-symmetric tensors of type~$(0,s)$ has
dimension~$\begin{pmatrix}d\\s\end{pmatrix}$.  Thus, if~$M$ is
a~$d$-dimensional manifold, the set of~$d$-forms~$\Omega^d(M)$ is pointwise
unidimensional.  Its elements are called~\emph{densities} on~$M$.
Similarly~$0$-forms are also uni-dimensional, and its elements are
called~\emph{potentials}.  The~$1$-forms are locally~$d$-dimensional and they
are called~\emph{gradients}.  Thus in dimension~$d>1$ we will always have two
types of ``scalar fields'' and two types of ``vector fields'':

\begin{tabular}{l|l|l|l}
	set & local dimension & meaning & units \\
	\hline
	$\Omega^0(M)=C^\infty(M)$ & 1 & scalar fields, potentials & $[]$ \\
	$\Omega^d(M)$ & 1 & densities & $[L^{-d}]$ \\
	$\Omega^1(M)$ & d & gradients & $[L^{-1}]$ \\
	$\mathcal{X}(M)$ & d& flows & $[L]$ \\
\end{tabular}

The~\emph{wedge product} is the map
\[
	\bigwedge:\Omega^p(M)\times\Omega^q(M)\to\Omega^{p+q}(M)
\]
defined by anti-symmetrizing the tensor product
\[
	\omega\wedge\eta=\frac{p+q}{p!q!}\mathrm{Alt}(\omega\otimes\eta).
\]

Since this definition is too abstract, let us see how it works out in~$\R^2$
and~$\R^3$.  Let us start with the canonical coordinate
functions~$x,y,z:\R^3\to\R$, etc.  They give rise to the canonical basis for
vector fields~$\ds\left\{
	\frac\partial{\partial x},
	\frac\partial{\partial y},
	\frac\partial{\partial z}
\right\}
$, which in turn can be used to define the canonical basis of~$1$-forms as
its dual base~$\left\{\ud x, \ud y, \ud z\right\}$.  By now this is just a
funky notation for the dual basis, but on the next section we will see
that~$\ud x$ is the~``$\ud$'' operator applied to the function~$x$.
Canonical bases of higher-order forms are obtained by taking wedge products
of~$1$-forms:

\begin{tabular}{l|l|l|l}
	set & dimension & basis & meaning \\
	\hline
	$\mathcal{X}(\R^2)$ & 2 &
	$\frac\partial{\partial x}, \frac\partial{\partial y}$ &
	flows, speeds \\
	$C^\infty(\R^2)=\Omega^0(\R^2)$ & 1 & $1$ & scalars, potentials\\
	$\Omega^1(\R^2)$ & 2 & $\ud x, \ud y$ & gradients, line elements\\
	$\Omega^2(\R^2)$ & 1 & $\ud x\wedge \ud y$ & densities, area elements\\
	\hline
	$\mathcal{X}(\R^3)$ & 3 &
	$\frac\partial{\partial x}, \frac\partial{\partial y},
	\frac\partial{\partial z}$ & flows, speeds\\
	$C^\infty(\R^3)=\Omega^0(\R^3)$ & 1 & $1$ & scalars, potentials\\
	$\Omega^1(\R^3)$ & 3 & $\ud x, \ud y, \ud z$ & gradients, line elements\\
	$\Omega^2(\R^3)$ & 3 &
	$\ud y\!\wedge\!\ud z, \ud z\!\wedge\!\ud x, \ud x\!\wedge\!\ud
	y$ & surface elements\\
	$\Omega^3(\R^3)$ & 1 & $\ud x\wedge\ud y\wedge\ud z$ & densities, volume
	elements\\
\end{tabular}

Notice that, in dimension~$2$ we have two types of ``vector fields'': flows
and gradients.  In dimension~$3$ we have three types: flows, gradients, and
surface elements.  Notice that you typically do different things with them:
actual vector fields (elements of~$\mathcal{X}(\R^3)$ are used to compute
directional derivatives of functions, or to compute the integral lines of the
flow they represent.  Elements of~$\Omega^0$ are evaluated at single points.
Elements of~$\Omega^1$ are integrated along lines.  Elements of~$\Omega^2$
are integrated along surfaces (e.g., to compute a flux).  Elements
of~$\Omega^p$ are integrated along volumes.  In general, we'll say
that~$p$-forms are integrated along~$p$-chains.

In higher dimensions, elements of~$\Omega^p(\R^d)$ can be expressed uniquely
as
\[
	\omega  =
	\sum_{1\le i_1\le\cdots\le i_p\le d}
	\omega_{i_1,\ldots,i_p} \ud x^{i_1}\wedge\cdots\wedge\ud x^{i_p}
\]
or simply~$\ds\omega=\sum_I\omega_I\ud x^I$
where~$I$ is an ``alternating multi-index'' and each of the~${d\choose p}$
functions~$w_I$ belongs to~$C^\infty(M)$.

\subsection{exterior derivative, closed forms, betti numbers}

The~\emph{exterior derivative} is the~$\R$-linear map (or rather sequence of maps):
\[
	\ud :\Omega^p(M) \to \Omega^{p+1}(M)
\]
defined by
\[
	\ud\left( \sum_I\omega_I\ud x^I \right)
=\sum_I \sum_{i=1}^d\frac{\partial\omega_I}{\partial x^i}\ud x^i
	\wedge\ud x^I
\]
It has the following three properties, which together are equivalent to the
definition
\[
	\omega\in\Omega^p
	\quad\implies\quad
	\ud\left(\ud\omega\right)=0
\]
\[
	f\in\Omega^0(M)
	\quad\implies\quad
	\ud f =
	\frac{\partial f}{\partial x^1}\ud x^1
	+\cdots+
	\frac{\partial f}{\partial x^d}\ud x^d
\]
\[
	f\in\Omega^p,g\in\Omega^q
	\quad\implies\quad
	\ud\left(\omega\wedge\eta\right)
	=
	\left(\ud\omega\right)\wedge\eta
	+
	(-1)^p
	\left(
		\omega\wedge\ud\eta
	\right)
\]
If~$f$ is a function, then~$\ud f$ is the unique~$1$-form such
that~$\left(\ud f\right)(X)=X\left(f\right)$ for all vector fields~$X$.

The exterior derivative generalizes the common first-order differential
operators of vector calculus: gradient, divergence, curl.  However,
since~$\ud^2=0$ it cannot be used to define any second-order operator, like
the Laplacian or the Hessian.  For that, we will need further structure in
the base manifold (a Riemannian metric).

The following table shows the exterior derivative on the canonical basis
of~$\R^d$ for~$d=1,2,3$.  Partial derivatives are denoted by sub-indices.

\begin{tabular}{l|l|l}
	map & coordinate expression & meaning \\
	\hline
	$\ud:\Omega^0(\R^1)\to\Omega^1(\R^1)$ &
	$\ud\left(f\right) = f'\ud x$ &
	derivative\\
	\hline
	$\ud:\Omega^0(\R^2)\to\Omega^1(\R^2)$ &
	$\ud\left(f\right) = f_x\ud x + f_y\ud y$ &
	gradient \\
	$\ud:\Omega^1(\R^2)\to\Omega^2(\R^2)$ &
	$\ud\left(P\ud x+Q\ud y\right) = \left(Q_x-P_y\right)\ud x\wedge\ud y$ &
	2D curl, $\mathrm{div}(P,Q)^\perp$ \\
	\hline
	$\ud:\Omega^0(\R^3)\to\Omega^1(\R^3)$ &
	$\ud\left(f\right) = f_x\ud x + f_y\ud y + f_z\ud z$ &
	gradient \\
	$\ud:\Omega^1(\R^3)\to\Omega^2(\R^3)$ &
	\footnotesize
	$\ud\!\left(P\ud x\!+\!Q\ud y\!+\!R\ud z\right) =
	\left(R_y\!-\!Q_z\right)\!\ud y\ud z
	+
	\left(P_z\!-\!R_x\right)\!\ud z\ud x
	+
	\left(Q_x\!-\!P_y\right)\!\ud x\ud y$
	&
	curl \\
	$\ud:\Omega^2(\R^3)\to\Omega^3(\R^3)$ &
	$\ud\left(P\ud y\ud z+Q\ud z\ud x+R\ud x\ud y\right)
	=\left(P_x+Q_y+R_z\right)\ud x\ud y\ud z$
	&
	divergence
\end{tabular}

All these expressions follow directly from the definition.  For
example~$\ud\left(P\ud x+Q\ud y\right)=
\left(P_x\ud x+P_y\ud y\right)\ud x+\left(Q_x\ud x+Q_y\ud y\right)\ud y
=\left(Q_x-P_y\right)\ud x\ud y$, where we have used the alternating
property
$\ud x\ud x=0$,~$\ud y\wedge\ud x=-\ud x\wedge\ud y$ to simplify the last
expression.

If~$M$ is a~$d$-dimensional manifold, we have a sequence of linear maps
called the~\emph{de Rham complex}:
\[
	0
	\to
	\Omega^0(M)
	\to
	\Omega^1(M)
	\to\cdots\to
	\Omega^{d-1}(M)
	\to
	\Omega^d(M)
	\to
	0
\]
The dimensions of the resulting quotient spaces are the~\emph{Betti numbers}
of the manifold~$M$.  The first Betti number is the number of connected
components of~$M$, the second is the number of~$1$-dimensional holes, and so
on.

In more detail, we say that a~$p$-form~$\omega$ is~\emph{closed}
if~$\ud\omega=0$.  We say that a~$p$-form~$\omega$ is~\emph{exact} if there
exists some~$(p-1)$-form~$\eta$ such that~$\ud\eta=\omega$.  The
relation~$\ud^2=0$ says that all exact forms are closed (e.g., in~$\R^3$ the
gradient of a constant is zero, the curl of a gradient is zero, the
divergence of a curl is zero).  In general, there may be closed forms that
are not exact; this will depend on the topology of the manifold~$M$.  The quotient of vector
subspaces~$\textrm{closed $p$-forms}/\textrm{exact $p$-forms}$ measures how
many non-exact closed~$p$-forms are there.  Its dimension is the~$p$-th Betti
number.

For~$p=0$,
the condition of being closed~($\ud f=0$) means that~$f$ is constant on each
connected component of~$M$, and the condition of being exact means
that~$f$ is globally constant.  The~$0$-th Betti  number is thus the number
of connected components.
In~$\R^d$, all closed~$p$-forms for~$p\ge1$ are exact, so its sequence of
Betti numbers is~$(1,0,0,\ldots,0)$.

\subsection{chains, integrals and stokes theorem}

A~\emph{$p$-chain} is a domain were~$p$-forms can be integrated (optionally,
with some multiplicity).  For example,~$0$-chains are formal linear
combinations of points of~$M$, $1$-chains are formal linear combinations of
curve segments on~$M$ and so on.  In general, a~$p$-chain is a formal linear
combination of embedded hypercubes (or simplexes).

The~\emph{integral} of a~$d$-form~$\omega\ud x^1\wedge\cdots\wedge\ud x^d$
over a~$d$-dimensional embedded hypercube~$c:[0,1]^d\to M$ can be defined
using a local chart~$\varphi:M\to\R^d$, using the Riemann integral of the
function~$\varphi\circ c$.  This is extended to arbitrary chains by
linearity, and to~$p$-chains by a similar construction.  Notice that for the
composition~$\varphi\circ c$ to make sense we need that the image of~$c$ be
small enough to fit on the domain of the chart, if this is not the case, we
can always cut the hypercube into small enough parts.

The Boundary operator~$\partial$ is defined so that it transforms~$p$-chains
into~$(p-1)$-chains.  For example the image of a curve
segment~$\gamma:[a,b]\to M$ is a~$1$-chain, and its boundary is
the~$0$-chain~$\gamma(b)-\gamma(a)$.

Once integrals over~$p$-forms and~$p$-chains have been defined,~\emph{Stokes
theorem} is the observation that the boundary operator is the adjoint of the
exterior derivative:
\[
	\int_\Omega\ud\omega=\int_{\partial\Omega}\omega
\]
where~$\omega$ is a~$p$-form and~$\Omega$ is a~$(p+1)$-chain.

For~$M=\R$ and~$p=1$, this is simply the fundamental theorem of calculus:
set~$\Omega=[a,b]$ so
that~$\partial\Omega=\left\{-a,b\right\}$,~$\omega:\R\to\R$,
then~$\ud\omega=\omega'(x)\ud x$ so that
\[
	\int_{[a,b]}\omega'(x)\ud x = \omega(b)-\omega(a)
\]
A similar correspondence recovers the classical Green, Gauss and Stokes
theorems as particular cases.

\clearpage
\subsection{currents and forms}

Stokes theorem is so beautiful and symmetric... but the
notation could be improved a bit, couldn't it?  We would like to write
something like
\[
	\left\langle
	\Omega,\ \ud\omega
	\right\rangle
	=
	\left\langle
	\ud^*\Omega,\ \omega
	\right\rangle
\]
so that the boundary operator is~\emph{defined} as the adjoint of the
exterior derivative with respect to the pairing, and Stokes theorem itself is
a notational triviality.  But what is the
pairing~$\left\langle\cdot,\cdot\right\rangle$ here?  Over what objects does
it act upon?

The answer, beautifully laid out by Goerges de Rham
%(at the suggestion of Laurent Schwartz)
on his book~\emph{Variétés différentiables : formes,
courants, formes harmoniques}, is to use distribution theory.  The boundary
operator is defined as the distributional derivative of (oriented) indicator
functions.

For example, in dimension~$1$ we can write the integral~$\int_{[a,b]}f(x)\ud x$
as~$\int_\R\1_{[a,b]}(x)f(x)\ud x$.  Now, note that the derivative of the
indicator function~$\1_{[a,b]}$ is a sum of two Diracs at the boundary points:
\[
	{\1_{[a,b]}}'(x)=\delta(x-a)-\delta(x-b)
\]
Thus the fundamental theorem of calculus is just the integral of the product
rule for derivatives:
\[
	\left(\1_{[a,b]}(x)f(x)\right)'={\1_{[a,b]}}'(x)f(x)+\1_{[a,b]}(x)f'(x)
\]
which, after integration over all of~$\R$ becomes
\[
	0 = f(a)-f(b)+\int_{[a,b]}f'(x)\ud x
\]

In higher dimensions everything is laid up very beautifully.  For example,
the divergence theorem
\[
	\int_{\partial\Omega} \vec F\cdot\vec{\ud n} =
	\int_\Omega\mathrm{div}\left(\vec F\right)
\]
can be written as
\[
	-\int_{\R^3}
	\vec F\cdot \nabla\1_\Omega
	=
	\int_{\R^3}
	\1_\Omega\ \mathrm{div}\left(\vec F\right)
\]
which comes formally from the product rule of the divergence
\[
	\mathrm{div}\left(fG\right)=f\mathrm{div}G+G\cdot\nabla f
\]
Intuitively, the gradient of the indicator function~$\1_\Omega$ is a vector field of
diracs supported at the boundary, pointing towards the inside of~$\Omega$.
Hence, the minus sign, because in the divergence theorem the normal
field~$\vec n$ must point towards the outside.

In general, distributions that use~$p$-forms as test functions are
called~\emph{currents}.  Equivalently, currents are differential forms where
the coefficients are distributions instead of functions.
Chains and forms are particular cases of currents.

This construction is very important and extremely natural for the discrete case.
In some sense the discrete case is much easier: a Dirac is just a function
that takes the value~$1$ at a single point, and~$0$ elsewhere.  There is no
distinction between functions and distribtions in the discrete case.
Everything is continuous and smooth in the discrete case (!).
The objects to integrate, and the domains where they are integrated, are just
vectors.
Integrals are
scalar products of these vectors.   Once we have
defined all the objects carefully, the discrete Stokes theorem will amount to
the associativity of matrix products.

\clearpage
\subsection{lie bracket}

Vector fields convert functions into functions:~$X(f)$ is the
directional derivative of the function~$f$ in the direction of~$X$.
Thus, we can apply them in series, to compute second derivatives $X(Y(f))$.

It may come as a surprise that the commutator of two vector fields,
named the~\emph{Lie bracket}
\[
	[X,Y]f := X(Y(f)) - Y(X(f))
\]
is not a second derivative, but a first derivative (!).
%This is one of the most amazing facts in mathematics.

We can check that~$[X,Y]$ is a vector field according to each of the
definitions (F1), (F2), (F3) above.  Each one provides a different insight.
In all cases, we have to verify that
\begin{equation}\label{eq:liederivation}
	[X,Y](fg) = f[X,Y]g + g[X,Y]f
\end{equation}
These verifications are very important here because we will try to re-do them
on the discrete case, where each one fails for different reasons.  None of the
possible ``immediate'' definitions of a discrete Lie bracket are
satisfactory.

To check definition (F1), the verification is straightforward. If we develop the
expression~$[X,Y](fg)$ we find that many terms cancel out, and what remains
is formula~(\ref{eq:liederivation}) above:
\begin{align*}
	[X,Y]\left(fg\right) &= X\left(fYg+gYf\right)-Y\left(fXg+gXf\right) \\
	&= X\left(fYg\right)+X\left(gYf\right)-Y\left(fXg\right)-Y\left(gXf\right) \\
	&= fXYg + XfYg + gXYf + XgYf - fYXg - YfXg - gYXf - YgXf\\
	&= f(XYg-YXg) + g(XYf-YXf) \\
	&= f[X,Y]g + g[X,Y]f
\end{align*}
Notice that this proof is general: the commutator of two
derivations is always a derivation.

Using the coordinates of vector fields, as in definition~(F3), gives
essentially the same proof.  But here it is easier to see how all the second
derivatives get cancelled.  Recall that the action of a vector
field~$X=\left(a^i\frac\partial{\partial x^2}\right)_{i=1,\ldots,d}$ over a
function~$f$ is the directional derivative~$\nabla_Xf=X\cdot\nabla f$:
\[
	Xf = \sum_ia^i\frac{\partial f}{\partial x^i}
\]
So that
\begin{align*}
	XYf &= \sum_ia^i\frac{\partial }{\partial x^i}
	\left(
		\sum_j b^j\frac{\partial f}{\partial x^j}
	\right)
	\\
	&= \sum_ia^i\sum_j\left(
		\frac{\partial b^j}{\partial x^i}
		\frac{\partial f}{\partial x^j}
		+b^j\frac{\partial^2f}{\partial x^ix^j}
	\right)
\end{align*}
Notice that the term that contains second
derivatives~$a^ib^j\frac{\partial^2f}{\partial x^ix^j}$ is symmetric with
respect to both vector fields.  Thus when computing~$XY-YX$ it disappears,
and only the first derivatives remain:
$$
[X,Y]f = \sum_j
\left(
	\sum_i
	a^i\frac{\partial b^j}{\partial x^i}
	-
	b^i\frac{\partial a^j}{\partial x^i}
\right)
\frac{\partial f}{\partial x^j}
$$
This means that~$[X,Y]$ is indeed a vector field, and its coordinates are
$
\left(
	a^i\frac{\partial b^j}{\partial x^i}
	-
	b^i\frac{\partial a^j}{\partial x^i}
\right)
$.

A different insight is obtained by considering the flows associated to the
vector fields, as in definition (F2).  Recall that to each vector field~$X$
corresponds a flow field~$\phi^X_t:M\to M$ such that~$\phi^X_0(p)=p$,
$\left.\frac{\ud}{\ud t}\right|_{t=0}\phi^X_t(p)=X_p$.  The last equality
meaning that for all functions~$f\in C^\infty(M)$ we have
$\left.\frac{\ud}{\ud t}\right|_{t=0}f(\phi^X_t(p))=X_p(f)=(Xf)(p)$.  Or,
writing the derivatives in terms of limits,
\[
	(Xf)(p) = \lim_{t\to0}\frac{f\circ\phi^X_t(p)-f(p)}t
\]
Thus we can write~$XYf$ as
\begin{align*}
	\left(XYf\right)(p)
	&= \lim_{t\to0}\frac{(Yf)\circ\phi^X_t(p)-(Yf)(p)}{t}\\
	&= \lim_{t\to0}\frac{\ds
		\lim_{h\to 0}\frac{f\circ\phi^Y_h\circ\phi^X_t(p)-f\circ\phi^X_t(p)}h
		-\lim_{h\to 0}\frac{f\circ\phi^Y_h(p)-f(p)}h
	}t\\
	&= \lim_{t\to0}\frac{
		f\circ\phi^Y_t\circ\phi^X_t(p)-f\circ\phi^X_t(p)-f\circ\phi^Y_t(p)-f(p)
	}{t^2}
\end{align*}
where we have set~$t=h$ to obtain the last expression.

Now, by computing the commutator~$XY-YX$ the terms with just one flow disappear:
\[
	([X,Y]f)(p) =
	\lim_{t\to0}\frac{
		f\circ\phi^Y_t\circ\phi^X_t(p)
		-
		f\circ\phi^X_t\circ\phi^Y_t(p)
	}{t^2}
\]
This is apparently~\emph{not} a tangent vector at~$p$ (the first derivative of a
smooth curve through~$p$).  There are two ``immediate'' things that we can do
with this limit.  First, a change of variable~$t^2=h$.  Second, we
replace~$p$ by~$\phi^Y_{-t}\phi^X_{-t}(q)$ for a point~$q$ that ``tends
to~$p$''.  Both manipulations are subtle and require detailed justification.
But in the end we have
\[
	[X,Y]f(p)=\lim_{h\to0}\frac{
		f\circ\phi^Y_{\sqrt h}\circ\phi^X_{\sqrt h}
		\circ\phi^Y_{-\sqrt h}\circ\phi^X_{-\sqrt h}(p)
		-f(p)
	}h
\]
which can be seen to be a tangent vector.



\subsection{lie derivatives (of functions, forms, tensors)}

Given a vector field~$X$ The~\emph{Lie derivative~$L_X$} transforms tensor
fields into tensor fields of the same type.  In particular, it transforms
functions into functions, vector fields into vector fields, and~$k$-forms
into~$k$-forms.

The definition in terms of flows is this:
\[
	L_X T(p)=\lim_{t\to0}\frac{\left(\phi^X_t\right)^*_pT\left(\phi^X_t(p)\right)-T(p)}t
\]
where~$\left(\phi^X_t\right)^*_p$ is the pullback map between the
tangent spaces~$T_pM$ and~$T_{\phi^X_t(p)}$ (extended to all tensor
layers).  The pullback is necessary because~$T(p)$ and~$T(\phi(p))$ live in
different vector spaces and cannot be subtracted directly.  Notice that by
construction~$L_XT$ is of the same type as~$T$.

The Lie derivative has the following properties, which together are
equivalent to the definition:

(L1) $L_Xf=Y(f)$

(L2) $L_X(S\otimes T)=(L_XS)\otimes T+S\otimes(L_XT)$

(L3) $L_X(T(Y_1,\ldots,Y_n))
=
(L_XT)(Y_1,\ldots,Y_n)
+T((L_XY_1),\ldots,Y_n)
+\cdots
+T(Y_1,\ldots,(L_XY_n))
$

(L4) $[L_x,\ud]=0$


Some interesting particular cases. The Lie derivative of a vector field is
the Lie bracket:~$L_XY=[X,Y]$ (!)

The Lie derivative of a function is the contraction with its differential
\(L_Xf=\mathcal{i}_X\ud f\).

More generally, the Lie derivative of a~$k$-form can be written in terms of
contractions and differentials, according to Cartan's magic formula:
\[
	L_X\omega=\mathcal{i}_X\ud\omega+\ud\left(\mathcal{i}_X\omega\right)
\]

\clearpage
\subsection{summary of differential geometry}

Spaces:

\begin{tabular}{l|l}
	\hline
	$M$ & manifold \\
	$C^\infty(M)$ & functions on $M$ \\
	$TM$ & tangent bundle \\
	$\mathcal{X}(M)$ & vector fields \\
	$\mathcal{T}^{r,s}(M)$ & tensor fields of type $(r,s)$ \\
	$\Omega^p(M)$ & differential forms of degree $p$\\
	$\mathcal{S}^k(M)$ & $k$-chains on~$M$
\end{tabular}

Note that~$\mathcal{T}^{0,0}=C^\infty$,
$\mathcal{T}^{1,0}=\mathcal{X}$ and~$\Omega^p$ is the subset
of~$\mathcal{T}^{0,p}$ made of alternating tensors.


\bigskip

Objects:

\begin{tabular}{l|l}
	\hline
	$p\in M$ & a point in the manifold \\
	$f\in C^\infty(M)$ &a function \\
	$f(p)\in\R$ & function evaluated at a point \\
	$X\in \mathcal{X}(M)$ & a vector field \\
	$X(f)\in C^\infty(M)$ & derivative of~$f$ in the direction of~$X$ \\
	$\omega\in \Omega^1(M)$ & a 1-form \\
	$\omega(X)\in C^\infty(M)$ & $\omega$ applied to~$X$ \\
\end{tabular}


\bigskip

Maps:

\begin{tabular}{l|l}
	\hline
	$\partial:\mathcal{S}^k\to\mathcal{S}^{k-1}$ & boundary of chains \\
	$\int:\mathcal{S}^k\times\Omega^k\to\R$ & integral of a~$k$-form on
	a~$k$-chain \\
	$\mathcal{i}_X:\mathcal{T}^{r,s}\to\mathcal{T}^{r,s-1}$ & contraction of
	tensors by the vector field~$X$\\
	$\bigotimes:\mathcal{T}^{r,s}\times\mathcal{T}^{r'\!,\,s'}\to
	\mathcal{T}^{r+r'\/,\,s+s'}$ & tensor product \\
	$\bigwedge:\Omega^p\times\Omega^q\to\Omega^{p+q}$ & wedge product \\
	$\ud:\Omega^p\to\Omega^{p+1}$ & exterior derivative \\
	$\mathcal{i}_X:\Omega^p\to\Omega^{p-1}$ & interior product of forms by the
	vector field~$X$ \\
	$[\cdot,\cdot]:\mathcal{X}\times\mathcal{X}\to\mathcal{X}$ & Lie bracket of
	two vector fields \\
	$L_X:\mathcal{T}^{r,s}\to\mathcal{T}^{r,s}$ & Lie derivative of tensors by
	the vector field~$X$ \\
\end{tabular}


%\bigskip
\clearpage

Properties:

\begin{tabular}{l|l}
	\hline
	$X(fg)=fX(g)+gX(f)$ & $X$ is a derivation \\
	$(\ud f)(X)=X(f)$ & $\nabla_Xf=X\cdot \nabla f$\\
	$d^2=0$ & exact forms are closed \\
	$\partial^2=0$ & boundaries have no boundary \\
	$\int_{\partial\Omega}\omega=\int_\Omega\ud\omega$ & Stokes formula \\
	$\ud\left(\omega\wedge\eta\right)=
	\ud\omega\wedge\eta+(-1)^p\omega\wedge\ud\eta$ &
	$\ud$ is an anti-derivation (of degree~$1$)\\
	$\mathcal{i}_X\left(\omega\wedge\eta\right)=
	\mathcal{i}_X\omega\wedge\eta+(-1)^p\omega\wedge\mathcal{i}_X\eta$
	& $\mathcal{i}_X$ is an anti-derivation (of degree~$-1$)\\
	$L_X\left(S\otimes T\right)=
	\left(L_XS\right)\otimes T
	+
	S\otimes\left(L_XT\right)
	$ & $L_X$ is a derivation on~$\mathcal{T}^{r,s}$\\
	$L_X\left(\omega\wedge\eta\right)=
	\left(L_X\omega\right)\wedge\eta
	+
	\omega\wedge\left(L_X\eta\right)
	$ & $L_X$ is a derivation on~$\Omega^k$\\
	$L_Xf=X(f)$ & Lie derivative of functions is the directional derivative\\
	$L_XY=[X,Y]$ & Lie derivative of vectors is the Lie bracket\\
	$L_X\omega=\mathcal{i}_X\ud\omega+\ud\left(\mathcal{i}_X\omega\right)$ &
	Cartan's magic formula \\
	$\ud L_X\omega=L_X\left(\ud\omega\right)$ &
	Lie derivative commutes with exterior derivative\\
	$L_{fX}\omega=fL_X\omega+\ud f\wedge i_X\omega$ &
	non~$C^\infty(M)$-linearity of~$L_X$ wrt~$X$\\
	$[X,[Y,Z]]+[Y,[Z,X]]+[Z,[X,Y]]=0$ & Jacobi identity\\
	$L_X[Y,Z]=[L_XY,Z]+[Y,L_XZ]$ &
	Jacobi says~$L_X$ is derivation wrt Lie bracket\\
	$[L_x,\mathcal{i}_Y]\omega=
	[\mathcal{i}_X,L_Y]\omega=
	\mathcal{i}_{[X,Y]}\omega$ & whatever, there are many identities like this\\
\end{tabular}



\clearpage
\section{Riemannian geometry}

% GRAND SCHEME OF METRIC STUFF WITH METRIC-ONLY STUFF IN RED

\subsection{metric, length, energy}

\subsection{geodesic equations}

\subsection{musical isomorphisms, hodge duality}

\subsection{laplace beltrami}

\subsection{covariant derivative}

\subsection{parallel transport}

\subsection{killing vector fields (infinitessimal isometries)}

\subsection{hessian}

\subsection{curvatures}


\clearpage
\section{Other structured geometries}

\subsection{symplectic structure}

poisson bracket, volume form, cotangent bundle

\subsection{complex structure}

\subsection{kahlerian structure}


\clearpage
\section{Discrete case}



% vim:set tw=77 filetype=tex spell spelllang=en sw=2 ts=2:
